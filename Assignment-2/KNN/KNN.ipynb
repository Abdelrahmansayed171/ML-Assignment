{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class k_nearest_neighbors():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.train=list()\n",
    "\n",
    "    def __euclidean_distance(self,row_1, row_2):\n",
    "        distance = 0.0\n",
    "        for i in range(len(row_1)-1):\n",
    "            distance += (row_1[i] - row_2[i])**2\n",
    "        return distance**(1/2) \n",
    "\n",
    "\n",
    "    def __neighbors(self,test_row, k):\n",
    "        distances = list()\n",
    "        for train_row in self.train:\n",
    "                dist = self.__euclidean_distance(test_row, train_row)\n",
    "                distances.append((train_row, dist))\n",
    "                distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors_with_distances=distances[:k]\n",
    "        return neighbors_with_distances   #Tuples of k neighbors and their distances\n",
    "    \n",
    "\n",
    "    def predict(self, test_row, k):\n",
    "        nwd = self.__neighbors(test_row, k) #Neighbors with distance\n",
    "        total_weighted_votes = {}\n",
    "        total_weights = 0\n",
    "\n",
    "        for neighbor, dist in nwd:\n",
    "            weight = 1 / (dist + 0.000001) #to not divide by 0\n",
    "            total_weights += weight\n",
    "\n",
    "            class_label = neighbor[-1]\n",
    "\n",
    "            if class_label in total_weighted_votes:\n",
    "                total_weighted_votes[class_label] += weight\n",
    "            else:\n",
    "                total_weighted_votes[class_label] = weight\n",
    "\n",
    "        normalized_votes = {label: weight / total_weights for label, weight in total_weighted_votes.items()} #Weight of every class divided by total weights of both classes\n",
    "        return max(normalized_votes, key=normalized_votes.get) #Max voted class\n",
    "\n",
    "    def eval_metric(self,actual, predicted):\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct\n",
    "        \n",
    "    def fit(self,train, test, num_neighbors):\n",
    "        self.train=train\n",
    "        predicted_values = list()\n",
    "        for row in test:\n",
    "            output = self.predict(row, num_neighbors)\n",
    "            predicted_values.append(output)\n",
    "        actual_values = [row[-1] for row in test]\n",
    "        corr=self.eval_metric(actual_values,predicted_values)\n",
    "        print(\"Model fit successfully using:- \\nK: {}\\nCorrect predicitons: {}\\nTest set instances: {}\\nAccuracy: {}%\".format(num_neighbors,corr,len(test),str(round(corr / len(test) * 100,2))))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing():\n",
    "\n",
    "    def train_test_split(dataset,ratio):\n",
    "        \n",
    "        ratio_idx=round(1-ratio*len(dataset))\n",
    "        train = dataset[:ratio_idx]\n",
    "        test = dataset[ratio_idx:]\n",
    "        return train, test\n",
    "    \n",
    "    def normalize(dataset):\n",
    "\n",
    "        features = [list(map(float, row[:-1])) for row in dataset]\n",
    "        labels = [row[-1] for row in dataset]\n",
    "\n",
    "        features_transposed = list(map(list, zip(*features)))\n",
    "\n",
    "        # Normalization min max\n",
    "        normalized_features = []\n",
    "        for feature_values in features_transposed:\n",
    "            min_value = min(feature_values)\n",
    "            max_value = max(feature_values)\n",
    "            normalized_feature = [(float(value) - min_value) / (max_value - min_value) for value in feature_values]\n",
    "            normalized_features.append(normalized_feature)\n",
    "\n",
    "        normalized_features = list(map(list, zip(*normalized_features)))\n",
    "\n",
    "        normalized_dataset = [normalized_feature + [label] for normalized_feature, label in zip(normalized_features, labels)]\n",
    "\n",
    "        return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pd:\n",
    "    \n",
    "    def read_csv(filename,header=True):\n",
    "        with open(filename, 'r') as f:\n",
    "            if header:\n",
    "                next(f)\n",
    "            results = []\n",
    "            for line in f:\n",
    "                line= line.strip()\n",
    "                words = line.split(',')\n",
    "                results.append(words)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=preprocessing.normalize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=preprocessing.train_test_split(dataset,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=k_nearest_neighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit successfully using:- \n",
      "K: 5\n",
      "Correct predicitons: 173\n",
      "Test set instances: 229\n",
      "Accuracy: 75.55%\n"
     ]
    }
   ],
   "source": [
    "knn.fit(train,test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit successfully using:- \n",
      "K: 3\n",
      "Correct predicitons: 175\n",
      "Test set instances: 229\n",
      "Accuracy: 76.42%\n",
      "────────────────────\n",
      "Model fit successfully using:- \n",
      "K: 6\n",
      "Correct predicitons: 176\n",
      "Test set instances: 229\n",
      "Accuracy: 76.86%\n",
      "────────────────────\n",
      "Model fit successfully using:- \n",
      "K: 9\n",
      "Correct predicitons: 171\n",
      "Test set instances: 229\n",
      "Accuracy: 74.67%\n",
      "────────────────────\n",
      "Model fit successfully using:- \n",
      "K: 12\n",
      "Correct predicitons: 177\n",
      "Test set instances: 229\n",
      "Accuracy: 77.29%\n",
      "────────────────────\n",
      "Model fit successfully using:- \n",
      "K: 14\n",
      "Correct predicitons: 178\n",
      "Test set instances: 229\n",
      "Accuracy: 77.73%\n",
      "────────────────────\n"
     ]
    }
   ],
   "source": [
    "for k in [3,6,9,12,14]:\n",
    "    knn.fit(train,test,k)\n",
    "    print('─' * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
